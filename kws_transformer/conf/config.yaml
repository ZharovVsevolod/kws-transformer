model:
  name: transformer_kws
  layers: 12
  heads: 2
  mlp_dim: 512
  num_output_classes: 11
  embedding_dim: 256
  norm_type: postnorm
  dropout: 0.1

data:
  path_to_data: ./dataset
  sample_rate: 16000
  time_window: 100
  frequency: 40
  patch_size_time: 20
  patch_size_freq: 8
  n_mels: 40
  hop_length: 161
  dataset_size: 100

training:
  project_name: kws-transformer
  train_name: new_era_2024_1
  batch: 512
  lr: 3e-4
  epochs: 50
  model_path: /weights
  wandb_path: /wandb
  save_best_of: 3
  checkpoint_monitor: val_loss
  early_stopping_patience: 30

scheduler_train:
  type_of_scheduler: ReduceOnPlateau
  patience_reduce: 5
  factor_reduce: 0.1
  lr_coef_cycle: 1